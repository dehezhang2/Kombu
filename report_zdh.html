<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Comupter Graphics Final Project Report">
    <title>Final Project Report â€“ Deheng Zhang & Ganlin Zhang</title>

    <link rel="stylesheet" href="./assets/pure.css">
    <!--[if lte IE 8]>
        <link rel="stylesheet" href="css/side-menu-old-ie.css">
    <![endif]-->
    <!--[if gt IE 8]><!-->
        <link rel="stylesheet" href="./assets/side-menu.css">
    <!--<![endif]-->
    <link href="./assets/twentytwenty.css" rel="stylesheet" type="text/css" />
<style type="text/css"></style></head>

<body data-new-gr-c-s-check-loaded="14.1087.0" data-gr-ext-installed="">
<div class="container contentWrapper">
<div id="layout">
    <!-- Menu toggle -->
    <a href="./index.html#menu" id="menuLink" class="menu-link">
        <!-- Hamburger icon -->
        <span></span>
    </a>
    <div id="menu">
        <div class="pure-menu pure-menu-open">
            <a href="./index.html">Final Project</a>
            <ul>
                <li class="menu-item-divided pure-menu">
                    <a href="./index.html">Rendering Result</a>
                </li>
                <li class="menu-item-divided pure-menu">
                    <a href="./proposal.html">Proposal</a>
                </li>
                <li class="menu-item-divided pure-menu">
                    <a href="./report_zgl.html">Ganlin Zhang</a>
                </li>
                <li class="menu-item-divided pure-menu-selected">
                    <a href="./report_zdh.html">Deheng Zhang</a>
                </li>
            </ul>
        </div>
    </div>

    <div id="main">
        <div class="header">
            <h2>Project Report</h2>
            <h3 style="margin: 0 0 10px 0">Deheng Zhang</h3>
        </div>
        <div class="content">
            <h3>Participate Media</h3>
            <h4>Heterogeneous Participating Media (30 points)</h4>  
            <h5 style="margin: 0 0 0 0">Relevant code:</h5>           
            <ul>
                <li class="codelist"><code>include/kombu/medium.h</code></li>
                <li class="codelist"><code>include/kombu/phase.h</code></li>
                <li class="codelist"><code>include/kombu/volume.h</code></li>
                <li class="codelist"><code>src/mediums/homogeneous.cpp</code></li>
                <li class="codelist"><code>src/mediums/heterogeneous.cpp</code></li>
                <li class="codelist"><code>src/phase/isotropic.cpp</code></li>
                <li class="codelist"><code>src/volumes/constvolume.cpp</code></li>
                <li class="codelist"><code>src/volumes/gridvolume.cpp</code></li>
                <li class="codelist"><code>src/integrators/vol_path_mats.cpp</code></li>
                <li class="codelist"><code>src/integrators/vol_path_mis.cpp</code></li>
            </ul>
            
            <p>
                Since we created chimneys with smoke on the house, I implemented heterogeneous participate medium. I start this by 
                implementing a <code>HomogeneousMedium</code> class with simple path tracing integrator <code> vol_path_mats</code>. Note
                that our medium can be only attached to a specific shape. This is achieved by adding free path sampling and phase function sampling to the <code> path_mats</code> when the origin
                of current recursive ray is in the medium. Besides, the three channels color information is considered in the homogeneous medium. 
                After that, I implemented a more complex <code>vol_path_mis</code> integrator
                , which extends the <code>path_mis</code> integrator. This integrator is tricky because we need to consider:
                <ul>
                    <li>Correctly calculate the MIS weight (for medium and surface cases), and normalize the weight for delta sampling.</li>
                    <li>Recursively check the shadow ray intersection, multiply the transmittance if the ray go through a medium.</li>
                    <li>Recursively check the emitter intersection.</li>
                </ul>
                Then, the <code>HeterogeneousMedium</code> is implemented with the <code>Volume</code> data structure. Currently there are two types
                of volume : <code>ConstVolume</code> and <code>GridVolume</code>. The later one can read the same data format as mitsuba with the help 
                of the external libray <code>Qt4</code>. 
            </p>
            <h5 style="margin: 0 0 0 0">Validation:</h5>
            <p>
                1. Homogeneous medium and vol_path_mis integrator: <br/>
                As shown in the following figure (cbox with 128 samples per pixel), the <code>vol_path_mis</code> integrator has better performance than the <code>vol_path_mats</code>
                integrator. And our integrator has similar result compared to mitsuba (our noise is even smaller than mitsuba). The parameters are:<br/>
                Left ball:
                $$\sigma_t = (6, 3, 2), albedo = (0.167, 0.333, 0.5)$$
                Right ball:
                $$\sigma_t = (2, 3, 6), albedo = (0.5, 0.333, 0.167)$$
                <div class="center">

                    <div class="twentytwenty-container">
                        <img src="./assets/validation/volumetric/cbox_vol_path_mats.png" alt="vol_path_mats" class="img-responsive">
                        <img src="./assets/validation/volumetric/cbox_vol_path_mis.png" alt="vol_path_mis" class="img-responsive">
                        <img src="./assets/validation/volumetric/cbox_vol_path_misuba_color.png" alt="mitsuba" class="img-responsive">
                    </div> <br>
                </div>
                The comparison with different scattering coefficient is shown below:<br/>
                
                No scattering: \(albedo_l = albedo_r = (0, 0, 0)\) <br/>
                Full scattering: \(albedo_l = albedo_r = (1, 1, 1)\) <br/>
                <div class="twentytwenty-container">
                    <img src="./assets/validation/volumetric/cbox_vol_path_mis_no_scatter.png" alt="no scatter" class="img-responsive">
                    <img src="./assets/validation/volumetric/cbox_vol_path_mis_full_scatter.png" alt="full scatter" class="img-responsive">
                    <img src="./assets/validation/volumetric/cbox_vol_path_misuba_no_scatter.png" alt="no scatter mitsuba" class="img-responsive">
                    <img src="./assets/validation/volumetric/cbox_vol_path_misuba_full_scatter.png" alt="full scatter mitsuba" class="img-responsive">
                </div> <br>
                Besides, our integrator can pass all the previous tests:<br/>
                test-furnace
                <pre><code class="language-pascal">
Generating 100000 paths.. 
Sample mean = 5.02035 (reference value = 5)
Sample variance = 8.1692
t-statistic = 2.25163 (d.o.f. = 99999)
Accepted the null hypothesis (p-value = 0.0243476, significance level = 0.00250943)

Passed 4/4 tests.
                </code></pre>
                test-direct
                <pre><code class="language-pascal">
Generating 100000 paths.. 
Sample mean = 0.261954 (reference value = 0.26174)
Sample variance = 0.0195052
t-statistic = 0.484854 (d.o.f. = 99999)
Accepted the null hypothesis (p-value = 0.627781, significance level = 0.00100453)

Passed 10/10 tests.
                </code></pre>
                2.  Heterogeneous: <br/>
                As shown in the first figure, the heterogeneous medium with <code>ConstVolume</code> has the same result as 
                our homogeneous participating medium. And as shown in the second figure, <code>GridVolume</code> has the similar result 
                as mitsuba.
                <div class="twentytwenty-container">
                    <img src="./assets/validation/volumetric/cbox_homo_const.png" alt="homogeneous" class="img-responsive">
                    <img src="./assets/validation/volumetric/cbox_heter_const.png" alt="heterogeneous" class="img-responsive">
                </div> <br>
                <div class="twentytwenty-container">
                    <img src="./assets/validation/volumetric/hetvol.png" alt="mitsuba" class="img-responsive">
                    <img src="./assets/validation/volumetric/hetvol_nori_stratify_denoised.png" alt="our" class="img-responsive">
                </div> <br>
            </p>
            <h4>Different distance sampling (transmittance) estimation methods (10 points)</h4>  
            <h5 style="margin: 0 0 0 0">Relevant code:</h5>
            <ul>
                <li class="codelist"><code>src/mediums/heterogeneous.cpp</code></li>
            </ul>
            <p>I also implemented different methods for free path sampling and transmittance estimation.
                Note that transmittance is used when calculating the recursive shadow ray to the emitter. 
                For delta tracking and ratio tracking, the free path sampling methods are the same (i.e. use
                the majorant density to sample the distance, then use the real density for rejection). However, 
                the transmittance estimation is slightly different. For delta tracking, the transmittance is estimated
                using a \(0-1\) distribution of passing through the meidum, and for ratio tracking, we multiply the ratio of fictitious density 
                and majorant density \(1 - {\sigma_t(x) \over \bar \sigma_t}\) for each majorant sampling step, because this is the probability of
                passing through this sample (no rejection). 
            </p>
            <p>For ray marching, similar to Mitsuba, I use Simpson quadrature to compute the integral:
                $$
                    integral = \int_{ray.mint}^{ray.maxt} \sigma_t(ray(x)) dx
                $$
                For transmittance estimation, we simply use the \(e^{-integral}\) as the transmittance. And for 
                free path sampling, I integrate the density until:
                $$
                    \int_{ray.mint}^{t} \sigma_t(ray(x)) dx > -ln(1- \xi)
                $$
                Then, Lagrange polynomial is used to find the specific point such that the equality is held.
            </p>
            <h5 style="margin: 0 0 0 0">Validation:</h5>
            <p>As shown in the validation for heterogeneous medium (the smoke), our delta tracking has the similar result as 
            mitsuba. The following figure shows our ray marching result compared with mitsuba. Note that since transmittance is only 
            used for shadow rays, we only need to observe the shadow of the smoke.
                <div class="twentytwenty-container">
                    <img src="./assets/validation/volumetric/hetvol_march.png" alt="mitsuba" class="img-responsive">
                    <img src="./assets/validation/volumetric/hetvol_nori_march_256.png" alt="our" class="img-responsive">
                </div> <br>
            </p>
            
            <p>Since mitsuba doesn't implement ratio tracking, I validate this feature by showing it has smaller variance. 
                The following figure compares the ray marching, ratio tracking and delta tracking with sampling per pixel 32. 
                As expected, ratio tracking performs slightly better than delta tracking. And ray marching has better performance 
                in the shadow part. This is because ray marching uses more samples for transmittance integration compared with unbiased
                methods.
                <div class="twentytwenty-container">
                    <img src="./assets/validation/volumetric/hetvol_nori_delta.png" alt="delta" class="img-responsive">
                    <img src="./assets/validation/volumetric/hetvol_nori_ratio.png" alt="ratio" class="img-responsive">
                    <img src="./assets/validation/volumetric/hetvol_nori_march.png" alt="march" class="img-responsive">
                </div> <br>
                The following image shows the error metric between our three methods and mitsuba result. 
                Note that the mean error \(0.001\) comes from the right bottom corner logo of mitsuba render. 
                The variance is a little bit lower for ratio tracking compared with delta tracking. Since the ray marching is a biased
                estimator, mean of the error distribution is shifted compared with other two methods. We can still find that the shadow part
                of ray marching is better than other two methods.
                <div class="twentytwenty-container">
                    <img src="./assets/validation/volumetric/error_nori_delta.jpg" alt="delta" class="img-responsive">
                    <img src="./assets/validation/volumetric/error_nori_ratio.jpg" alt="ratio" class="img-responsive">
                    <img src="./assets/validation/volumetric/error_nori_march.jpg" alt="march" class="img-responsive">
                </div> <br>

            </p>
                
            <h4>Anisotropic Phase Function (5 points)</h4>  
            <h5 style="margin: 0 0 0 0">Relevant code:</h5>
            <ul>
                <li class="codelist"><code>include/kombu/phase.h</code></li>
                <li class="codelist"><code>src/phase/hg.cpp</code></li>
                <li class="codelist"><code>src/sample/warp.cpp</code></li>
                <li class="codelist"><code>src/tests/warptest.cpp</code></li>
            </ul>
            <p>For Henyey-Greenstein phase function, I implemented a new sampling method in the <code>warp.cpp</code>, and a new phase function
                class. I also implemented a warptest to validate the result.
            </p>
            <h5 style="margin: 0 0 0 0">Validation:</h5>
            <p>
                As shown in the following image, all the parameters are the same as previous tests, the only difference is that, for the left ball 
                \(g = 0.5\), and for the right ball \(g = -0.5\). The following figure shows a comparison between our implementation and Mitsuba. 
                Our methods have similar performance as mitsuba, even better in terms of noise.
                <div class="twentytwenty-container">
                    <img src="./assets/validation/volumetric/cbox_vol_path_mis.png" alt="isotropic" class="img-responsive">
                    <img src="./assets/validation/volumetric/cbox_vol_path_misuba_color.png" alt="isotropic mitsuba" class="img-responsive">
                    <img src="./assets/validation/volumetric/cbox_vol_path_mis_hg.png" alt="hg" class="img-responsive">
                    <img src="./assets/validation/volumetric/cbox_vol_path_misuba_hg.png" alt="hg mitsuba" class="img-responsive">
                </div> <br>
                Besides, the result of warp test is shown below:
                <img src="./assets/validation/volumetric/hg_validate.gif" alt="isotropic" class="img-responsive" width = "99%">
            </p>
            <h3>Basic Denoising: Bilateral Filter with Uniform Variance (5 points)</h3>
            <h4 style="margin: 0 0 0 0">Relevant code:</h4>
            <p>
                <ul>
                    <li class="codelist"><code>include/kombu/denoiser.h</code></li>
                    <li class="codelist"><code>src/utils/bilaterial.cpp</code></li>
                    <li class="codelist"><code>src/utils/nl_means.cpp</code></li>
                    <li class="codelist"><code>src/core/render.cpp</code></li>
                </ul>
                For denoiser, I implemented basic bilaterial denoiser as well as NL means denoiser 
                with uniform variance. Since NL means preserves better structure information, it is used 
                for validation. The idea is to compute patch-wise color distance and report distance
                 around the center pixel and use its exponential as weight to filter the image. 
            </p>
            <h4 style="margin: 0 0 0 0">Validation:</h4>
            <p>
                As shown in the following image, our denoiser can reduce the noise. Used in conjunction with our stratified sampler, 
                the performance is much more better than the individual sampling without denoising. 
                <div class="twentytwenty-container">
                    <img src="./assets/validation/volumetric/hetvol_nori.png" alt="independent" class="img-responsive">
                    <img src="./assets/validation/volumetric/hetvol_nori_denoised.png" alt="independent + denoise" class="img-responsive">
                    <img src="./assets/validation/volumetric/hetvol_nori_stratify.png" alt="stratified" class="img-responsive">
                    <img src="./assets/validation/volumetric/hetvol_nori_stratify_denoised.png" alt="stratified + denoise" class="img-responsive">
                </div> <br>
                The following figure shows that the variance of the error is reduced after denoising after stratified sampling and denoising:
                <div class="twentytwenty-container">
                    <img src="./assets/validation/volumetric/error.jpg" alt="independent" class="img-responsive">
                    <img src="./assets/validation/volumetric/error_denoised.jpg" alt="independent + denoise" class="img-responsive">
                    <img src="./assets/validation/volumetric/error_stratify.jpg" alt="stratified" class="img-responsive">
                    <img src="./assets/validation/volumetric/error_stratify_denoised.jpg" alt="stratified + denoise" class="img-responsive">
                </div> <br>
            </p>
            
            <h3>Simple Extra Emitters: directional light (5 points)</h3>
            <h4 style="margin: 0 0 0 0">Relevant code:</h4>
            <p>
                <ul>
                    <li class="codelist"><code>src/emitters/directional.cpp</code></li>
                    <li class="codelist"><code>src/integrators/direct_ems.cpp</code></li>
                    <li class="codelist"><code>src/integrators/direct_mis.cpp</code></li>
                    <li class="codelist"><code>src/integrators/path_mis.cpp</code></li>
                    <li class="codelist"><code>src/integrators/vol_path_mis.cpp</code></li>
                </ul>
                For directional light, the <code>eval()</code> and <code>pdf()</code> methods are trivial,
                since it is a delta light (just return 0 and 1). However, in order to calculate the transmittance 
                between the emitter and the query point, we need to assign a 3D point in the sampling function. 
                We first get the bounding sphere of the scene, and find the intersection of the directional light 
                direction starting from the center of the sphere. Then we project the vector from the query point to the 
                intersection point to the directional light direction. The projected point is used as the point for light 
                sampling. Although it is not an accurate solution, but it is more efficient. <br/>
                Another tricky issue is that for MIS, similar to the delta BSDF, the delta light is impossible to be hit by 
                the ray sampled by BSDF. Therefore, we normalize the \(w_{ems} = 1, w_{mat} = 0\) for delta light.
            </p>

            <h4 style="margin: 0 0 0 0">Validation:</h4>
            <p>
                As shown in the following figure, our directional light works well with different light direction, and has the 
                same result as mitsuba:
                <div class="twentytwenty-container">
                    <img src="./assets/validation/directional/ajax-mitsuba-pos.gif" alt="mitsuba" class="img-responsive">
                    <img src="./assets/validation/directional/ajax-av-pos.gif" alt="our" class="img-responsive">
                </div> <br>
                
            </p>
            <h3>Object Instancing (5 points)</h3>
            <h4 style="margin: 0 0 0 0">Relevant code:</h4>
            <p>
                <ul>
                    <li class="codelist"><code>include/kombu/instance.h</code></li>
                    <li class="codelist"><code>include/kombu/reference.h</code></li>
                    <li class="codelist"><code>src/geometry/instance.cpp</code></li>
                    <li class="codelist"><code>src/geometry/reference.cpp</code></li>
                    <li class="codelist"><code>src/core/scene.cpp</code></li>
                </ul>
                For the object instancing, I implement one object (shape class) instancing 
                without shape group (since the multiple intersection checking is a bit tricky). 
                My implementation cannot add child to instance, but only allow the transformation of 
                the reference object. For all instances that point to the reference object, all geometry operations
                are transformed to the local frame of the instance and call the corresponding function in the reference object. 
            </p>
            <h4 style="margin: 0 0 0 0">Validation:</h4>
            <p>
                I compare the result of object instancing with the result using two seperate spheres, these two cases should have the same
                output image. Also, I show the spheres with texture to prove the rotation is correct. 
                <div class="twentytwenty-container">
                    <img src="./assets/validation/object_instance/cbox.png" alt="no instance" class="img-responsive">
                    <img src="./assets/validation/object_instance/cbox_instance.png" alt="instance" class="img-responsive">
                    <img src="./assets/validation/object_instance/cbox_instance_texture.png" alt="instance with texture" class="img-responsive">
                </div> <br>
            </p>            
            
        </div>
    </div>
</div>

<script src="./assets/ui.js"></script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
<script src="assets/jquery.twentytwenty.js"></script>

<script>
    $(window).load(function(){$(".twentytwenty-container").twentytwenty({default_offset_pct: 0.5});});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

</div></body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>